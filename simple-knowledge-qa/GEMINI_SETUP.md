# Setup with Google Gemini

## Quick Setup (5 minutes)

### Step 1: Get Google Gemini API Key (FREE!)

1. Go to: https://makersuite.google.com/app/apikey
2. Click "Create API Key"
3. Copy your API key (starts with `AIza...`)

**Note**: Gemini has a generous free tier!

---

### Step 2: Configure Environment

1. **Create .env file** in project root:
   ```bash
   # In VS Code terminal
   cp .env.example .env
   ```

2. **Edit .env file** (use VS Code):
   - Open `.env` file
   - Replace `your_gemini_api_key_here` with your actual key
   - Save the file

   Example:
   ```
   GEMINI_API_KEY=AIzaSyD_your_actual_key_here
   PORT=8000
   ```

---

### Step 3: Install New Dependencies

```bash
# Make sure venv is activated (you should see (venv) in terminal)
pip install -r requirements.txt --upgrade
```

This will install:
- `google-generativeai` - Gemini SDK
- `python-dotenv` - For loading .env file

---

### Step 4: Restart the Server

1. **Stop the current server** (if running):
   - Press `Ctrl+C` in the terminal

2. **Start again**:
   ```bash
   python app.py
   ```

You should see:
```
‚úÖ Google Gemini initialized successfully
Loading embedding model: all-MiniLM-L6-v2
INFO:     Uvicorn running on http://0.0.0.0:8000
```

---

### Step 5: Test with Gemini

**Using browser** (easiest):

1. Go to: http://localhost:8000/docs

2. **Check Status**:
   - Click `GET /status`
   - Click "Try it out" ‚Üí "Execute"
   - You should see:
     ```json
     {
       "llm": {
         "provider": "Google Gemini",
         "model": "gemini-pro",
         "status": "healthy"
       }
     }
     ```

3. **Upload Document**:
   - Click `POST /upload`
   - Upload `sample-documents/machine-learning.txt`

4. **Ask Question**:
   - Click `POST /ask`
   - Enter:
     ```json
     {
       "question": "What is supervised learning?"
     }
     ```
   - Click "Execute"
   - You should get a **natural language answer** generated by Gemini!

**Response will look like:**
```json
{
  "answer": "Supervised learning is a type of machine learning where...",
  "source": "machine-learning.txt",
  "similarity": 0.8234,
  "mode": "gemini",
  "sources_used": ["machine-learning.txt"]
}
```

---

## How It Works Now

### Before (Retrieval Only):
```
User Question ‚Üí FAISS Search ‚Üí Return Raw Chunk
```
**Problem**: Just returns a chunk of text, not a proper answer

### After (RAG with Gemini):
```
User Question ‚Üí FAISS Search ‚Üí Get Top 3 Chunks ‚Üí 
Gemini Generates Answer ‚Üí Return Natural Language Answer
```
**Benefit**: Natural, coherent answers based on your documents!

---

## Troubleshooting

### Error: "GEMINI_API_KEY not set"

**Fix**:
1. Make sure `.env` file exists in project root
2. Make sure you added your actual API key
3. Restart the server

### Error: "Gemini initialization failed"

**Check**:
1. API key is correct (no extra spaces)
2. API key is active at https://makersuite.google.com/app/apikey
3. Internet connection is working

### Fallback Mode

If Gemini fails, the system automatically falls back to retrieval-only mode:
```json
{
  "mode": "retrieval"
}
```

---

## Cost & Limits

**Gemini Free Tier:**
- ‚úÖ 60 requests per minute
- ‚úÖ 1 million tokens per day
- ‚úÖ Completely FREE

**Perfect for this project!**

---

## Example Questions That Work Well

After uploading `machine-learning.txt`:

‚ùì **"What is supervised learning?"**
‚úÖ Gets proper explanation with context

‚ùì **"Explain the difference between supervised and unsupervised learning"**
‚úÖ Gemini compares both from the document

‚ùì **"What are neural networks used for?"**
‚úÖ Clear answer about applications

---

## VS Code Quick Commands

```bash
# Stop server
Ctrl + C

# Restart server
python app.py

# Check if Gemini is working
curl http://localhost:8000/status

# Test question
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is machine learning?"}'
```

---

## Deployment with Gemini

When deploying to Render:

1. **Add Environment Variable**:
   - Go to your Render service
   - Settings ‚Üí Environment
   - Add: `GEMINI_API_KEY` = your key

2. **Deploy**:
   - Render will auto-deploy when you push to GitHub
   - Make sure not to commit your actual API key!

---

## Security Notes

‚ö†Ô∏è **NEVER commit your .env file to GitHub!**

The `.gitignore` already excludes it, but double-check:
```bash
# Make sure .env is in .gitignore
cat .gitignore | grep .env
```

---

## Success Checklist

- [ ] Got Gemini API key from Google
- [ ] Created `.env` file with API key
- [ ] Installed new dependencies
- [ ] Restarted server
- [ ] See "‚úÖ Google Gemini initialized successfully"
- [ ] `/status` shows Gemini as "healthy"
- [ ] Uploaded a document
- [ ] Asked a question
- [ ] Got natural language answer (not just a chunk)
- [ ] Response shows `"mode": "gemini"`

If all checked, you're ready! üéâ

---

## What Changed?

**Files Modified:**
1. ‚úÖ `requirements.txt` - Added Gemini SDK
2. ‚úÖ `app.py` - Integrated Gemini for answer generation
3. ‚úÖ `.env.example` - Added API key template

**New Features:**
- ‚úÖ Natural language answers (instead of raw chunks)
- ‚úÖ Multi-document context (uses top 3 chunks)
- ‚úÖ Automatic fallback if Gemini fails
- ‚úÖ Shows which mode was used (gemini vs retrieval)

---

Need help? Check the updated README.md or ask!
